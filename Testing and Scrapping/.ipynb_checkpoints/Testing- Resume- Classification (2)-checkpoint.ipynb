{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1090051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install selenium\n",
    "# pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\n",
    "# !pip install spacy==2.3.5\n",
    "# pip install pyresparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eecbc759",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7536/1436341932.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'punkt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'stopwords'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'wordnet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'omw-1.4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7b71a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e86c16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ankur\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator MultinomialNB from version 1.0.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "c:\\users\\ankur\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator LabelBinarizer from version 1.0.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "c:\\users\\ankur\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 1.0.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "c:\\users\\ankur\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator TfidfTransformer from version 1.0.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "c:\\users\\ankur\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 1.0.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "c:\\users\\ankur\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.0.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('NaiveBayes.pickle', 'rb') as efile:\n",
    "    clf=pickle.load(efile)\n",
    "with open('TFIDFVectorizer.pickle', 'rb') as efile:\n",
    "    word_vectorizer=pickle.load(efile)\n",
    "with open('LabelEncoder.pickle', 'rb') as efile:\n",
    "    le=pickle.load(efile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04873002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stop_words = set(stopwords.words('english')) #creating a set of stop words\n",
    "def cleanResume(resumeText):\n",
    "  \n",
    "    resumeText = re.sub('http\\S+\\s*', ' ', resumeText)  # remove URLs\n",
    "    resumeText = re.sub('RT|cc', ' ', resumeText)  # remove RT and cc\n",
    "    resumeText = re.sub('#\\S+', '', resumeText)  # remove hashtags\n",
    "    resumeText = re.sub('@\\S+', '  ', resumeText)  # remove mentions\n",
    "    resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', resumeText)  # remove punctuations\n",
    "    resumeText = re.sub(r'[^\\x00-\\x7f]',r' ', resumeText) \n",
    "    resumeText = re.sub('\\s+', ' ', resumeText)  # remove extra whitespace\n",
    "    word_tokens = word_tokenize(resumeText) #Tokenize words\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] #Contains words other than stop words\n",
    "    filtered_sentence = map(lambda x: lemmatizer.lemmatize(x), filtered_sentence)\n",
    "    \n",
    "    resumeText=' '.join(filtered_sentence)\n",
    "    return resumeText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18165cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_indices(ary, n):\n",
    "    flat = ary.flatten()\n",
    "    indices = np.argpartition(flat, -n)[-n:]\n",
    "    indices = indices[np.argsort(-flat[indices])]\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c096add0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(sent):\n",
    "  sent=cleanResume(sent)\n",
    "  WordFeatures = word_vectorizer.transform([sent])\n",
    "  x=largest_indices(clf.predict_proba(WordFeatures), 3)\n",
    "  recommendation=le.inverse_transform(x)\n",
    "  return recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83e4f68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyresparser import ResumeParser\n",
    "def resume_test(path):\n",
    "    data = ResumeParser(path).get_extracted_data()\n",
    "    sentences=\" \"\n",
    "    omit=[\"name\", \"email\", \"mobile_number\", \"no_of_pages\", \"total_experience\"]\n",
    "    for key, value in data.items():\n",
    "          if value !=None and key not in omit: \n",
    "            if type(value)==list:\n",
    "                  sentences= sentences +\" \"+ key + \" \" + \" \".join(value)\n",
    "            else:\n",
    "                  sentences= sentences +\" \"+ key + \" \" + value\n",
    "    professions= test(sentences)\n",
    "    return (professions,data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47d0f132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ankur\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\spacy\\util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "professions,data= resume_test('VithikaPungliya_Resume.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66cbd6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'VITHIKA PUNGLIYA',\n",
       " 'email': 'vithikapungliya25@gmail.com',\n",
       " 'mobile_number': '8484822102',\n",
       " 'skills': ['Ai',\n",
       "  'Opencv',\n",
       "  'Linux',\n",
       "  'Math',\n",
       "  'Numpy',\n",
       "  'Compliance',\n",
       "  'Technical',\n",
       "  'Analytics',\n",
       "  'Forecasting',\n",
       "  'Analysis',\n",
       "  'Github',\n",
       "  'Cloud',\n",
       "  'Video',\n",
       "  'C',\n",
       "  'Mining',\n",
       "  'Programming',\n",
       "  'Sql',\n",
       "  'Website',\n",
       "  'Architecture',\n",
       "  'Keras',\n",
       "  'Java',\n",
       "  'Audio',\n",
       "  'Research',\n",
       "  'Green',\n",
       "  'Python',\n",
       "  'Machine learning',\n",
       "  'Data analytics',\n",
       "  'Pandas',\n",
       "  'Matplotlib',\n",
       "  'Tensorflow',\n",
       "  'Communication',\n",
       "  'Parser',\n",
       "  'Database'],\n",
       " 'college_name': None,\n",
       " 'degree': None,\n",
       " 'designation': None,\n",
       " 'experience': ['Pune, India',\n",
       "  'June 2021 – Present',\n",
       "  'Pune Ploggers – A Pune based organization that carries out plogging activity.',\n",
       "  '•  Plogging drives are carried out on the weekend and the waste on hill slopes and riverbanks is gathered.',\n",
       "  'Green Hills – Tree Plantation on Hills',\n",
       "  '•  With the help of this organization, we have planted around 1000 trees on the hill slopes around Pune.',\n",
       "  'ReBooks – Redistribute your used Books',\n",
       "  '• This organization collects the used books and distributes them amongst the needy. This was partnered with the   MyPustak.com and the',\n",
       "  'books were made available on their website too.'],\n",
       " 'company_names': None,\n",
       " 'no_of_pages': 2,\n",
       " 'total_experience': 1.25}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c792e5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Science' 'Python Developer' 'Java Developer']\n"
     ]
    }
   ],
   "source": [
    "print(professions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26d02767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp/ipykernel_7536/639764183.py:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "df = pd.DataFrame(columns=['Title','Company','Ratings','Salary','Location','Job_Post_History','URL', 'Skills', \"Profession\"])\n",
    "for i in professions:\n",
    "    counter=counter+1\n",
    "    for j in range(1,3):\n",
    "        a=i.replace(\" \",\"-\")\n",
    "        b=i.replace(\" \",\"%20\")\n",
    "        url = f\"https://www.naukri.com/{a}-jobs-{j}?k={b}\"\n",
    "\n",
    "        driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "        driver.get(url)\n",
    "        time.sleep(1)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source,'html5lib')\n",
    "\n",
    "        driver.close()\n",
    "\n",
    "        results = soup.find(class_='list')\n",
    "        job_elems = results.find_all('article',class_='jobTuple bgWhite br4 mb-8')\n",
    "\n",
    "        for job_elem in job_elems:\n",
    "\n",
    "            # URL to apply for the job     \n",
    "            URL = job_elem.find('a',class_='title fw500 ellipsis').get('href')\n",
    "\n",
    "            # Post Title\n",
    "            Title = job_elem.find('a',class_='title fw500 ellipsis')\n",
    "\n",
    "            # Company Name\n",
    "            Company = job_elem.find('a',class_='subTitle ellipsis fleft')\n",
    "\n",
    "            # Ratings\n",
    "            rating_span = job_elem.find('span',class_='starRating fleft dot')\n",
    "            if rating_span is None:\n",
    "                continue\n",
    "            else:\n",
    "                Ratings = rating_span.text\n",
    "\n",
    "\n",
    "            # Salary offered for the job\n",
    "            Sal = job_elem.find('li',class_='fleft grey-text br2 placeHolderLi salary')\n",
    "            Sal_span = Sal.find('span',class_='ellipsis fleft fs12 lh16')\n",
    "            if Sal_span is None:\n",
    "                continue\n",
    "            else:\n",
    "                Salary = Sal_span.text\n",
    "\n",
    "            # Location for the job post\n",
    "            Loc = job_elem.find('li',class_='fleft grey-text br2 placeHolderLi location')\n",
    "            Loc_exp = Loc.find('span',class_='ellipsis fleft fs12 lh16')\n",
    "            if Loc_exp is None:\n",
    "                continue\n",
    "            else:\n",
    "                Location = Loc_exp.text\n",
    "\n",
    "            # Number of days since job posted\n",
    "            Hist = job_elem.find(\"div\",[\"type br2 fleft grey\",\"type br2 fleft green\"])\n",
    "            Post_Hist = Hist.find('span',class_='fleft fw500')\n",
    "            if Post_Hist is None:\n",
    "                continue\n",
    "            else:\n",
    "                Post_History = Post_Hist.text\n",
    "                \n",
    "            #Skills\n",
    "            skills=job_elem.find_all(\"ul\", [\"tags has-description\"])\n",
    "\n",
    "        #   Appending data to the DataFrame \n",
    "            df=df.append({'URL':URL,'Title':Title.text,'Company':Company.text,'Ratings':Ratings,'Salary':Salary,'Location':Location,'Job_Post_History':Post_History, \"Profession\":i,\"Profession_key\":counter, \"Skills\":skills},ignore_index = True)\n",
    "#         print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1228480",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display on Website\n",
    "#Every Profession highest cosine similarity 10\n",
    "#Profession\n",
    "#Company\n",
    "#Position\n",
    "#Ratings- Filter\n",
    "#Location\n",
    "#Job_Post_History\n",
    "#URL\n",
    "#Skills\n",
    "#Cosine Similiarty Index\n",
    "\n",
    "#Index\n",
    "#Resume Skills and Needed/Required Skills- Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947b41d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8188d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_list(ls):\n",
    "    ls=np.array(ls)\n",
    "    l=[]\n",
    "    \n",
    "    for x in np.nditer(ls):\n",
    "        l.append(str(x)) \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98ce3541",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Iteration of zero-sized operands is not enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7536/2028333498.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Skills\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Skills\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ankur\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4356\u001b[0m         \"\"\"\n\u001b[1;32m-> 4357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[1;32mc:\\users\\ankur\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ankur\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1097\u001b[0m                 \u001b[1;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 \u001b[1;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m                 mapped = lib.map_infer(\n\u001b[0m\u001b[0;32m   1100\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ankur\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7536/2920065027.py\u001b[0m in \u001b[0;36mconvert_list\u001b[1;34m(ls)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0ml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnditer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Iteration of zero-sized operands is not enabled"
     ]
    }
   ],
   "source": [
    "df[\"Skills\"]=df[\"Skills\"].apply(convert_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca95c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Skills\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28aebc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_skills=\" \".join(data[\"skills\"])\n",
    "user_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674256b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cv = CountVectorizer()\n",
    "def score(ls):\n",
    "    JobText=' '.join(ls)\n",
    "    text=[user_skills,JobText]\n",
    "    count_matrix = cv.fit_transform(text)\n",
    "    matchPercentage=cosine_similarity(count_matrix)[0][1] * 100\n",
    "    return round(matchPercentage, 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373ba1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score\"]=df[\"Skills\"].apply(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cff918",
   "metadata": {},
   "outputs": [],
   "source": [
    "top15=df.sort_values('score',ascending=False)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30be8ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job_Post_History</th>\n",
       "      <th>URL</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Profession_key</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lead - Data Science</td>\n",
       "      <td>United Phosphorus Limited</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>9 Days Ago</td>\n",
       "      <td>https://www.naukri.com/job-listings-lead-data-...</td>\n",
       "      <td>[Data Science, advanced analytics, digital ana...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Data Science Trainer</td>\n",
       "      <td>STARAGILE CONSULTING</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9,00,000 - 17,00,000 PA.</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "      <td>3 Days Ago</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scien...</td>\n",
       "      <td>[trainer, Business Intelligence tools, Data An...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring For AVP |Data Science  and Business Ana...</td>\n",
       "      <td>Citicorp Finance</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Pune, Bangalore/Bengaluru</td>\n",
       "      <td>3 Days Ago</td>\n",
       "      <td>https://www.naukri.com/job-listings-hiring-for...</td>\n",
       "      <td>[R, Data Science, python, Business Analytics, ...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Senior Software Engineer - Data Science</td>\n",
       "      <td>LogiNext</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>1 Day Ago</td>\n",
       "      <td>https://www.naukri.com/job-listings-senior-sof...</td>\n",
       "      <td>[IT Skills, Java, Python, Testing, Machine Lea...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Analyst-Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>1 Day Ago</td>\n",
       "      <td>https://www.naukri.com/job-listings-analyst-da...</td>\n",
       "      <td>[Publishing, Architecture, Consulting, Machine...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Senior Manager, Data Science And Analytics</td>\n",
       "      <td>TransUnion</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Pune</td>\n",
       "      <td>6 Days Ago</td>\n",
       "      <td>https://www.naukri.com/job-listings-senior-man...</td>\n",
       "      <td>[IT Skills, Java, Python, Data Science, Machin...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Senior Analyst-Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>6 Days Ago</td>\n",
       "      <td>https://www.naukri.com/job-listings-senior-ana...</td>\n",
       "      <td>[Publishing, Consulting, Predictive modeling, ...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Director Data Science</td>\n",
       "      <td>Optum</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>10 Days Ago</td>\n",
       "      <td>https://www.naukri.com/job-listings-director-d...</td>\n",
       "      <td>[Data Science, NLP, Business Analytics, data s...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Senior Analyst-Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>6 Days Ago</td>\n",
       "      <td>https://www.naukri.com/job-listings-senior-ana...</td>\n",
       "      <td>[Publishing, Artificial Intelligence, Consulti...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Software Engineer - Data Science</td>\n",
       "      <td>LogiNext</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>1 Day Ago</td>\n",
       "      <td>https://www.naukri.com/job-listings-software-e...</td>\n",
       "      <td>[Python, Tableau, Excel, data mining, Java, Ha...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Manager - Payments - Data Science</td>\n",
       "      <td>Bajaj Finserv</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Pune</td>\n",
       "      <td>7 Days Ago</td>\n",
       "      <td>https://www.naukri.com/job-listings-manager-pa...</td>\n",
       "      <td>[NoSQL, cassandra, Machine learning, Data coll...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Manager Data Science</td>\n",
       "      <td>Optum</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>1 Day Ago</td>\n",
       "      <td>https://www.naukri.com/job-listings-senior-man...</td>\n",
       "      <td>[Data Science, deep learning, SQL, NLP, Python...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Analyst-Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>6 Days Ago</td>\n",
       "      <td>https://www.naukri.com/job-listings-senior-ana...</td>\n",
       "      <td>[Publishing, Consulting, Predictive modeling, ...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analyst-Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>1 Day Ago</td>\n",
       "      <td>https://www.naukri.com/job-listings-analyst-da...</td>\n",
       "      <td>[Publishing, Consulting, Predictive modeling, ...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>Consilium Software</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>1 Day Ago</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scien...</td>\n",
       "      <td>[IT Skills, Java, Python, Data Science, Machin...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "18                                Lead - Data Science   \n",
       "26                               Data Science Trainer   \n",
       "9   Hiring For AVP |Data Science  and Business Ana...   \n",
       "14            Senior Software Engineer - Data Science   \n",
       "5                                Analyst-Data Science   \n",
       "21         Senior Manager, Data Science And Analytics   \n",
       "12                        Senior Analyst-Data Science   \n",
       "29                              Director Data Science   \n",
       "11                        Senior Analyst-Data Science   \n",
       "33                   Software Engineer - Data Science   \n",
       "22                  Manager - Payments - Data Science   \n",
       "8                         Senior Manager Data Science   \n",
       "6                         Senior Analyst-Data Science   \n",
       "2                                Analyst-Data Science   \n",
       "32                              Data Science Engineer   \n",
       "\n",
       "                      Company Ratings                    Salary  \\\n",
       "18  United Phosphorus Limited     4.3             Not disclosed   \n",
       "26       STARAGILE CONSULTING     5.0  9,00,000 - 17,00,000 PA.   \n",
       "9            Citicorp Finance     4.0             Not disclosed   \n",
       "14                   LogiNext     4.0             Not disclosed   \n",
       "5                   Accenture     4.2             Not disclosed   \n",
       "21                 TransUnion     4.3             Not disclosed   \n",
       "12                  Accenture     4.2             Not disclosed   \n",
       "29                      Optum     4.1             Not disclosed   \n",
       "11                  Accenture     4.2             Not disclosed   \n",
       "33                   LogiNext     4.0             Not disclosed   \n",
       "22              Bajaj Finserv     4.1             Not disclosed   \n",
       "8                       Optum     4.1             Not disclosed   \n",
       "6                   Accenture     4.2             Not disclosed   \n",
       "2                   Accenture     4.2             Not disclosed   \n",
       "32         Consilium Software     3.1             Not disclosed   \n",
       "\n",
       "                                             Location Job_Post_History  \\\n",
       "18                                Bangalore/Bengaluru       9 Days Ago   \n",
       "26  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...       3 Days Ago   \n",
       "9                           Pune, Bangalore/Bengaluru       3 Days Ago   \n",
       "14                                             Mumbai        1 Day Ago   \n",
       "5                                              Mumbai        1 Day Ago   \n",
       "21                                               Pune       6 Days Ago   \n",
       "12                                   Gurgaon/Gurugram       6 Days Ago   \n",
       "29                                   Gurgaon/Gurugram      10 Days Ago   \n",
       "11                                   Gurgaon/Gurugram       6 Days Ago   \n",
       "33                                             Mumbai        1 Day Ago   \n",
       "22                                               Pune       7 Days Ago   \n",
       "8                                 Bangalore/Bengaluru        1 Day Ago   \n",
       "6                                 Bangalore/Bengaluru       6 Days Ago   \n",
       "2                                 Bangalore/Bengaluru        1 Day Ago   \n",
       "32                                          New Delhi        1 Day Ago   \n",
       "\n",
       "                                                  URL  \\\n",
       "18  https://www.naukri.com/job-listings-lead-data-...   \n",
       "26  https://www.naukri.com/job-listings-data-scien...   \n",
       "9   https://www.naukri.com/job-listings-hiring-for...   \n",
       "14  https://www.naukri.com/job-listings-senior-sof...   \n",
       "5   https://www.naukri.com/job-listings-analyst-da...   \n",
       "21  https://www.naukri.com/job-listings-senior-man...   \n",
       "12  https://www.naukri.com/job-listings-senior-ana...   \n",
       "29  https://www.naukri.com/job-listings-director-d...   \n",
       "11  https://www.naukri.com/job-listings-senior-ana...   \n",
       "33  https://www.naukri.com/job-listings-software-e...   \n",
       "22  https://www.naukri.com/job-listings-manager-pa...   \n",
       "8   https://www.naukri.com/job-listings-senior-man...   \n",
       "6   https://www.naukri.com/job-listings-senior-ana...   \n",
       "2   https://www.naukri.com/job-listings-analyst-da...   \n",
       "32  https://www.naukri.com/job-listings-data-scien...   \n",
       "\n",
       "                                               Skills    Profession  \\\n",
       "18  [Data Science, advanced analytics, digital ana...  Data Science   \n",
       "26  [trainer, Business Intelligence tools, Data An...  Data Science   \n",
       "9   [R, Data Science, python, Business Analytics, ...  Data Science   \n",
       "14  [IT Skills, Java, Python, Testing, Machine Lea...  Data Science   \n",
       "5   [Publishing, Architecture, Consulting, Machine...  Data Science   \n",
       "21  [IT Skills, Java, Python, Data Science, Machin...  Data Science   \n",
       "12  [Publishing, Consulting, Predictive modeling, ...  Data Science   \n",
       "29  [Data Science, NLP, Business Analytics, data s...  Data Science   \n",
       "11  [Publishing, Artificial Intelligence, Consulti...  Data Science   \n",
       "33  [Python, Tableau, Excel, data mining, Java, Ha...  Data Science   \n",
       "22  [NoSQL, cassandra, Machine learning, Data coll...  Data Science   \n",
       "8   [Data Science, deep learning, SQL, NLP, Python...  Data Science   \n",
       "6   [Publishing, Consulting, Predictive modeling, ...  Data Science   \n",
       "2   [Publishing, Consulting, Predictive modeling, ...  Data Science   \n",
       "32  [IT Skills, Java, Python, Data Science, Machin...  Data Science   \n",
       "\n",
       "    Profession_key  score  \n",
       "18             1.0  37.50  \n",
       "26             1.0  36.38  \n",
       "9              1.0  34.02  \n",
       "14             1.0  32.36  \n",
       "5              1.0  31.62  \n",
       "21             1.0  30.15  \n",
       "12             1.0  30.12  \n",
       "29             1.0  30.00  \n",
       "11             1.0  28.87  \n",
       "33             1.0  27.78  \n",
       "22             1.0  27.50  \n",
       "8              1.0  26.73  \n",
       "6              1.0  26.73  \n",
       "2              1.0  26.73  \n",
       "32             1.0  26.09  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0264e5d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_sorted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m top5_2 \u001b[38;5;241m=\u001b[39m \u001b[43mdf_sorted\u001b[49m[df_sorted[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProfession_key\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2.0\u001b[39m ][:\u001b[38;5;241m5\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_sorted' is not defined"
     ]
    }
   ],
   "source": [
    "top5_2 = df_sorted[df_sorted['Profession_key'] == 2.0 ][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c66136",
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25253f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_3=df_sorted[df_sorted['Profession_key'] == 3.0 ][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f9004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97443b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdef0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef2c09c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
