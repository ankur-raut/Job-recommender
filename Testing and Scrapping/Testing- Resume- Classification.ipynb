{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c1090051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install selenium\n",
    "# !pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a8cd8995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyresparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7b71a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f379c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install spacy==2.3.5\n",
    "# !pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9aaeda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ae8d1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ankur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ankur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ankur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ankur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c03f7e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e86c16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ankur\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator MultinomialNB from version 1.0.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "c:\\users\\ankur\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator LabelBinarizer from version 1.0.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "c:\\users\\ankur\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 1.0.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('NaiveBayes.pickle', 'rb') as efile:\n",
    "    clf=pickle.load(efile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cadce3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ankur\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator TfidfTransformer from version 1.0.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "c:\\users\\ankur\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 1.0.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('TFIDFVectorizer.pickle', 'rb') as efile:\n",
    "    word_vectorizer=pickle.load(efile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0045b9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ankur\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.0.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('LabelEncoder.pickle', 'rb') as efile:\n",
    "    le=pickle.load(efile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04873002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stop_words = set(stopwords.words('english')) #creating a set of stop words\n",
    "def cleanResume(resumeText):\n",
    "  \n",
    "    resumeText = re.sub('http\\S+\\s*', ' ', resumeText)  # remove URLs\n",
    "    resumeText = re.sub('RT|cc', ' ', resumeText)  # remove RT and cc\n",
    "    resumeText = re.sub('#\\S+', '', resumeText)  # remove hashtags\n",
    "    resumeText = re.sub('@\\S+', '  ', resumeText)  # remove mentions\n",
    "    resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', resumeText)  # remove punctuations\n",
    "    resumeText = re.sub(r'[^\\x00-\\x7f]',r' ', resumeText) \n",
    "    resumeText = re.sub('\\s+', ' ', resumeText)  # remove extra whitespace\n",
    "    word_tokens = word_tokenize(resumeText) #Tokenize words\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] #Contains words other than stop words\n",
    "    filtered_sentence = map(lambda x: lemmatizer.lemmatize(x), filtered_sentence)\n",
    "    \n",
    "    resumeText=' '.join(filtered_sentence)\n",
    "    return resumeText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14f9c23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ankur\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\spacy\\util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "from pyresparser import ResumeParser\n",
    "data = ResumeParser('VithikaPungliya_Resume.pdf').get_extracted_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3739584",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=\" \"\n",
    "omit=[\"name\", \"email\", \"mobile_number\", \"no_of_pages\", \"total_experience\"]\n",
    "for key, value in data.items():\n",
    "      if value !=None and key not in omit: \n",
    "        if type(value)==list:\n",
    "              sentences= sentences +\" \"+ key + \" \" + \" \".join(value)\n",
    "        else:\n",
    "              sentences= sentences +\" \"+ key + \" \" + value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18165cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_indices(ary, n):\n",
    "    flat = ary.flatten()\n",
    "    indices = np.argpartition(flat, -n)[-n:]\n",
    "    indices = indices[np.argsort(-flat[indices])]\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c096add0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(sent):\n",
    "  sent=cleanResume(sent)\n",
    "  WordFeatures = word_vectorizer.transform([sent])\n",
    "  x=largest_indices(clf.predict_proba(WordFeatures), 3)\n",
    "  recommendation=le.inverse_transform(x)\n",
    "  return recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47d0f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "professions= test(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c792e5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Data Science', 'Python Developer', 'Java Developer'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "professions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "338e57fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26d02767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp/ipykernel_3788/469758879.py:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(\"chromedriver.exe\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3788/469758879.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'list'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mjob_elems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'article'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'jobTuple bgWhite br4 mb-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mjob_elem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjob_elems\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "df = pd.DataFrame(columns=['Title','Company','Ratings','Salary','Location','Job_Post_History','URL', 'Skills', \"Profession\"])\n",
    "for i in professions:\n",
    "    counter=counter+1\n",
    "    for j in range(1,3):\n",
    "        a=i.replace(\" \",\"-\")\n",
    "        b=i.replace(\" \",\"%20\")\n",
    "        url = f\"https://www.naukri.com/{a}-jobs-{j}?k={b}\"\n",
    "\n",
    "        driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "        driver.get(url)\n",
    "        time.sleep(1)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source,'html5lib')\n",
    "#         print(soup)\n",
    "\n",
    "        driver.close()\n",
    "\n",
    "        results = soup.find(class_='list')\n",
    "        print(results)\n",
    "        job_elems = results.find_all('article',class_='jobTuple bgWhite br4 mb-8')\n",
    "\n",
    "        for job_elem in job_elems:\n",
    "\n",
    "            # URL to apply for the job     \n",
    "            URL = job_elem.find('a',class_='title fw500 ellipsis').get('href')\n",
    "\n",
    "            # Post Title\n",
    "            Title = job_elem.find('a',class_='title fw500 ellipsis')\n",
    "\n",
    "            # Company Name\n",
    "            Company = job_elem.find('a',class_='subTitle ellipsis fleft')\n",
    "\n",
    "            # Ratings\n",
    "            rating_span = job_elem.find('span',class_='starRating fleft dot')\n",
    "            if rating_span is None:\n",
    "                continue\n",
    "            else:\n",
    "                Ratings = rating_span.text\n",
    "\n",
    "\n",
    "            # Salary offered for the job\n",
    "            Sal = job_elem.find('li',class_='fleft grey-text br2 placeHolderLi salary')\n",
    "            Sal_span = Sal.find('span',class_='ellipsis fleft fs12 lh16')\n",
    "            if Sal_span is None:\n",
    "                continue\n",
    "            else:\n",
    "                Salary = Sal_span.text\n",
    "\n",
    "            # Location for the job post\n",
    "            Loc = job_elem.find('li',class_='fleft grey-text br2 placeHolderLi location')\n",
    "            Loc_exp = Loc.find('span',class_='ellipsis fleft fs12 lh16')\n",
    "            if Loc_exp is None:\n",
    "                continue\n",
    "            else:\n",
    "                Location = Loc_exp.text\n",
    "\n",
    "            # Number of days since job posted\n",
    "            Hist = job_elem.find(\"div\",[\"type br2 fleft grey\",\"type br2 fleft green\"])\n",
    "            Post_Hist = Hist.find('span',class_='fleft fw500')\n",
    "            if Post_Hist is None:\n",
    "                continue\n",
    "            else:\n",
    "                Post_History = Post_Hist.text\n",
    "                \n",
    "            #Skills\n",
    "            skills=job_elem.find_all(\"ul\", [\"tags has-description\"])\n",
    "\n",
    "        #   Appending data to the DataFrame \n",
    "            df=df.append({'URL':URL,'Title':Title.text,'Company':Company.text,'Ratings':Ratings,'Salary':Salary,'Location':Location,'Job_Post_History':Post_History, \"Profession\":i,\"Profession_key\":counter, \"Skills\":skills},ignore_index = True)\n",
    "#         print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e1228480",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display on Website\n",
    "#Every Profession highest cosine similarity 10\n",
    "#Profession\n",
    "#Company\n",
    "#Position\n",
    "#Ratings- Filter\n",
    "#Location\n",
    "#Job_Post_History\n",
    "#URL\n",
    "#Skills\n",
    "#Cosine Similiarty Index\n",
    "\n",
    "#Index\n",
    "#Resume Skills and Needed/Required Skills- Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "947b41d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ce2d9c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job_Post_History</th>\n",
       "      <th>URL</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Profession_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Business Analyst - Data Science</td>\n",
       "      <td>Freshworks</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>1 Day Ago</td>\n",
       "      <td>https://www.naukri.com/job-listings-senior-bus...</td>\n",
       "      <td>[[[python], [PowerBI], [analytical], [Databric...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataiku Data Science Studio (DSS) Application ...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Pune</td>\n",
       "      <td>1 Day Ago</td>\n",
       "      <td>https://www.naukri.com/job-listings-dataiku-da...</td>\n",
       "      <td>[[[Business process], [MySQL], [Consulting], [...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analyst-Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>1 Day Ago</td>\n",
       "      <td>https://www.naukri.com/job-listings-analyst-da...</td>\n",
       "      <td>[[[Publishing], [Consulting], [Predictive mode...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analyst, Data Science &amp; Analytics</td>\n",
       "      <td>TransUnion</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Pune</td>\n",
       "      <td>5 Days Ago</td>\n",
       "      <td>https://www.naukri.com/job-listings-analyst-da...</td>\n",
       "      <td>[[[SQL], [communication], [IT Skills], [Data S...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>Rapido</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>1 Day Ago</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scien...</td>\n",
       "      <td>[[[Data Science], [data analysis], [NoSql], [A...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Senior Software Developer - JBPM/Java</td>\n",
       "      <td>SteerLean</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Kolkata, Mumbai, Visakhapatnam, Hyderabad/Secu...</td>\n",
       "      <td>Today</td>\n",
       "      <td>https://www.naukri.com/job-listings-senior-sof...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Sr. Java Developer / Lead</td>\n",
       "      <td>CIGNEX Datamatics</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Kolkata, Pune, Chennai, Bangalore/Bengaluru, D...</td>\n",
       "      <td>3 Days Ago</td>\n",
       "      <td>https://www.naukri.com/job-listings-sr-java-de...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Hiring Senior java Developers/Team Leads with ...</td>\n",
       "      <td>Netcracker</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Pune</td>\n",
       "      <td>1 Day Ago</td>\n",
       "      <td>https://www.naukri.com/job-listings-hiring-sen...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Senior Java Developer</td>\n",
       "      <td>V2Soft</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>1 Day Ago</td>\n",
       "      <td>https://www.naukri.com/job-listings-senior-jav...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Urgent Hiring || Java Full Stack Developer || ...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bhubaneswar, Kolkata, Hyderabad/Secunderabad, ...</td>\n",
       "      <td>1 Day Ago</td>\n",
       "      <td>https://www.naukri.com/job-listings-urgent-hir...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Java Developer</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title            Company  \\\n",
       "0              Senior Business Analyst - Data Science         Freshworks   \n",
       "1   Dataiku Data Science Studio (DSS) Application ...          Accenture   \n",
       "2                                Analyst-Data Science          Accenture   \n",
       "3                   Analyst, Data Science & Analytics         TransUnion   \n",
       "4                                Data Science Manager             Rapido   \n",
       "..                                                ...                ...   \n",
       "59              Senior Software Developer - JBPM/Java          SteerLean   \n",
       "60                          Sr. Java Developer / Lead  CIGNEX Datamatics   \n",
       "61  Hiring Senior java Developers/Team Leads with ...         Netcracker   \n",
       "62                              Senior Java Developer             V2Soft   \n",
       "63  Urgent Hiring || Java Full Stack Developer || ...              Wipro   \n",
       "\n",
       "   Ratings         Salary                                           Location  \\\n",
       "0      4.0  Not disclosed                                            Chennai   \n",
       "1      4.2  Not disclosed                                               Pune   \n",
       "2      4.2  Not disclosed                                Bangalore/Bengaluru   \n",
       "3      4.3  Not disclosed                                               Pune   \n",
       "4      4.0  Not disclosed                                Bangalore/Bengaluru   \n",
       "..     ...            ...                                                ...   \n",
       "59     3.6  Not disclosed  Kolkata, Mumbai, Visakhapatnam, Hyderabad/Secu...   \n",
       "60     4.3  Not disclosed  Kolkata, Pune, Chennai, Bangalore/Bengaluru, D...   \n",
       "61     3.8  Not disclosed                                               Pune   \n",
       "62     3.6  Not disclosed                                            Chennai   \n",
       "63     3.9  Not disclosed  Bhubaneswar, Kolkata, Hyderabad/Secunderabad, ...   \n",
       "\n",
       "   Job_Post_History                                                URL  \\\n",
       "0         1 Day Ago  https://www.naukri.com/job-listings-senior-bus...   \n",
       "1         1 Day Ago  https://www.naukri.com/job-listings-dataiku-da...   \n",
       "2         1 Day Ago  https://www.naukri.com/job-listings-analyst-da...   \n",
       "3        5 Days Ago  https://www.naukri.com/job-listings-analyst-da...   \n",
       "4         1 Day Ago  https://www.naukri.com/job-listings-data-scien...   \n",
       "..              ...                                                ...   \n",
       "59            Today  https://www.naukri.com/job-listings-senior-sof...   \n",
       "60       3 Days Ago  https://www.naukri.com/job-listings-sr-java-de...   \n",
       "61        1 Day Ago  https://www.naukri.com/job-listings-hiring-sen...   \n",
       "62        1 Day Ago  https://www.naukri.com/job-listings-senior-jav...   \n",
       "63        1 Day Ago  https://www.naukri.com/job-listings-urgent-hir...   \n",
       "\n",
       "                                               Skills      Profession  \\\n",
       "0   [[[python], [PowerBI], [analytical], [Databric...    Data Science   \n",
       "1   [[[Business process], [MySQL], [Consulting], [...    Data Science   \n",
       "2   [[[Publishing], [Consulting], [Predictive mode...    Data Science   \n",
       "3   [[[SQL], [communication], [IT Skills], [Data S...    Data Science   \n",
       "4   [[[Data Science], [data analysis], [NoSql], [A...    Data Science   \n",
       "..                                                ...             ...   \n",
       "59                                                 []  Java Developer   \n",
       "60                                                 []  Java Developer   \n",
       "61                                                 []  Java Developer   \n",
       "62                                                 []  Java Developer   \n",
       "63                                                 []  Java Developer   \n",
       "\n",
       "    Profession_key  \n",
       "0              1.0  \n",
       "1              1.0  \n",
       "2              1.0  \n",
       "3              1.0  \n",
       "4              1.0  \n",
       "..             ...  \n",
       "59             3.0  \n",
       "60             3.0  \n",
       "61             3.0  \n",
       "62             3.0  \n",
       "63             3.0  \n",
       "\n",
       "[64 rows x 10 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8188d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_list(ls):\n",
    "    ls=np.array(ls)\n",
    "    l=[]\n",
    "    \n",
    "    for x in np.nditer(ls):\n",
    "        l.append(str(x)) \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "98ce3541",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Iteration of zero-sized operands is not enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6736/2028333498.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Skills\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Skills\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ankur\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4356\u001b[0m         \"\"\"\n\u001b[1;32m-> 4357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[1;32mc:\\users\\ankur\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ankur\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1097\u001b[0m                 \u001b[1;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 \u001b[1;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m                 mapped = lib.map_infer(\n\u001b[0m\u001b[0;32m   1100\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ankur\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6736/2920065027.py\u001b[0m in \u001b[0;36mconvert_list\u001b[1;34m(ls)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0ml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnditer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Iteration of zero-sized operands is not enabled"
     ]
    }
   ],
   "source": [
    "df[\"Skills\"]=df[\"Skills\"].apply(convert_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7ca95c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [[[python], [PowerBI], [analytical], [Databric...\n",
       "1     [[[Business process], [MySQL], [Consulting], [...\n",
       "2     [[[Publishing], [Consulting], [Predictive mode...\n",
       "3     [[[SQL], [communication], [IT Skills], [Data S...\n",
       "4     [[[Data Science], [data analysis], [NoSql], [A...\n",
       "                            ...                        \n",
       "59                                                   []\n",
       "60                                                   []\n",
       "61                                                   []\n",
       "62                                                   []\n",
       "63                                                   []\n",
       "Name: Skills, Length: 64, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Skills\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28aebc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_skills=\" \".join(data[\"skills\"])\n",
    "user_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674256b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cv = CountVectorizer()\n",
    "def score(ls):\n",
    "    JobText=' '.join(ls)\n",
    "    text=[user_skills,JobText]\n",
    "    count_matrix = cv.fit_transform(text)\n",
    "    matchPercentage=cosine_similarity(count_matrix)[0][1] * 100\n",
    "    return round(matchPercentage, 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373ba1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score\"]=df[\"Skills\"].apply(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cff918",
   "metadata": {},
   "outputs": [],
   "source": [
    "top15=df.sort_values('score',ascending=False)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be8ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0264e5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_2 = df_sorted[df_sorted['Profession_key'] == 2.0 ][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c66136",
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25253f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_3=df_sorted[df_sorted['Profession_key'] == 3.0 ][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f9004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
